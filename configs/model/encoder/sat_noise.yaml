_target_: models.encoder.MaskedAttentionNoiseMapper
num_labels: ${dataset.num_labels}
num_latent_per_labels: 8
num_latents_bg: 8
latent_dim: 256
attention_latent_dim: 256
use_semantic_masking: True
num_blocks: 7
num_self_heads: 1
use_equalized_lr: False
lr_mul: 1.0